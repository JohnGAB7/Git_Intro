{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90701934-6743-42fd-80f9-091171f1477c",
   "metadata": {},
   "source": [
    "# Allianz Pricing: From Data Preparation to Risk Modeling Modeling (Modeling Part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c536c37-0926-46ca-a160-ac6e8f9ce439",
   "metadata": {},
   "source": [
    "## 1. Feature pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44185f6-1830-46f1-8e7b-127ffc659a46",
   "metadata": {
    "tags": []
   },
   "source": [
    "**[Add Context for Task 1]**\n",
    "\n",
    "The foundation of the premium is to choose a premium as per the risk of the customer. To do this, the risk of the customer seeking insurance, must be estimated. The underlying assumption is that there is a correlation between these variables and the risk.\n",
    "\n",
    "Feature pre-processing\n",
    "\n",
    "How to set a reasonable sub-groups (levels) for categorical variables is not always easy. But the main aim is to find as much homogeneity as possible within different class labels (levels) and every class label should receive a sufficient volume of observations. This can be done based on expert opinion or by resorting to some automatic algorithm to seek for homogeneity. \n",
    "\n",
    "Feature pre-processing in this section:\n",
    "\n",
    "`Area`: {A, ..., F} -> {1, ..., 6} (Has been set in previous exploratory data analysis section);\n",
    "\n",
    "`VehPower`: categorical feature, where we merge vehicle power groups bigger and equal to 9. In total, 6 classes based on expert opinion.\n",
    "\n",
    "`VehAge`: 3 categorical classes [0, 1), [1, 10), (10, +inf) based on expert opinion;\n",
    "\n",
    "`DrivAge`: 7 categorical classes [18; 21), [21; 26), [26; 31), [31; 41), [41; 51), [51; 71), [71;+inf) based on expert opinion.\n",
    "\n",
    "`BonusMalus`: continuous feature component (capping at value 150);\n",
    "\n",
    "`VehBrand`: categorical feature component (totally 11 classes);\n",
    "\n",
    "`VehGas`: binary feature component;\n",
    "\n",
    "`Density`: log-density is chosen as continuous log-linear feature component;\n",
    "\n",
    "`Region`: categorical feature component (totally 22 classes).\n",
    "\n",
    "Thus, we consider 3 continuous feature components (`Area`, `BonusMalus`, `log-Density`), 1 binary feature component (`VehGas`) and 5 categorical feature components (`VehPower`, `VehAge`, `DrivAge`, `VehBrand`, `Region`).\n",
    "\n",
    "\n",
    "## Good to know\n",
    "\n",
    "This project assumes you have a solid foundation in Python, statistics, and machine learning. Before attempting this project, it is recommended that you complete the prerequisite courses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef5a7e3-95b0-47a5-8fe6-bb198bb1dd25",
   "metadata": {},
   "source": [
    "**[Insert Instructions Below]**\n",
    "\n",
    "Please cut `VehAge` into 3 categorical bins [0, 1), [1, 10), (10, +inf), store the result in new variable `VehAgeGLM` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f627775-87b8-47cc-8921-c55efde22f0d",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee2f2d9-840a-4d65-9e00-cd33a6d8dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pol_clm_db = pd.read_csv('./datasets/pol_clm_db.csv')\n",
    "pol_clm_db['AreaGLM']         = pol_clm_db['Area']\n",
    "pol_clm_db['VehPowerGLM']     = pol_clm_db['VehPower'].astype(\"category\")\n",
    "pol_clm_db['VehAgeGLM']       = pd.cut(pol_clm_db['VehAge'],bins=[0, 9, np.inf])\n",
    "pol_clm_db['DrivAgeGLM']      = pd.cut(pol_clm_db['DrivAge'], [-np.inf, 21, 26, 31, 41, 51, 71, np.inf], right=False)\n",
    "pol_clm_db['BonusMalusGLM']   = pol_clm_db['BonusMalus'].astype('int')\n",
    "pol_clm_db['VehBrandGLM']     = pol_clm_db['VehBrand'].astype(\"category\")\n",
    "pol_clm_db['VehGasGLM']       = pol_clm_db['VehGas'].astype(\"category\")\n",
    "pol_clm_db['LogDensityGLM']   = pol_clm_db['LogDensity']\n",
    "pol_clm_db['RegionGLM']       = pol_clm_db['Region'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997f85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35ca89ac-9906-4fab-b292-0f341b70f81d",
   "metadata": {},
   "source": [
    "## 2. Create response variable for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054aa91-948b-4ae7-9cbe-1232af91dca3",
   "metadata": {},
   "source": [
    "**[Add Context for Task 2]**\n",
    "\n",
    "Create response variable for modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8fd25-7041-475b-a6e9-af81a6e3ec91",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "Create response variables for modeling part. Namely, frequency (`Frequency`) , severity (`Severity`), and pure premium (`PurePremium`). Please be careful when calculating the severity as there are lots of cases where number of claim is 0. Also, do the check if there exists any missing value for each explainable variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87377767-ef02-4bca-88a3-d3139180a50e",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ba4b4b-81a7-4ae3-955f-bcec66a03184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IDpol</th>\n",
       "      <th>ClaimNb</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Area</th>\n",
       "      <th>VehPower</th>\n",
       "      <th>VehAge</th>\n",
       "      <th>DrivAge</th>\n",
       "      <th>BonusMalus</th>\n",
       "      <th>VehBrand</th>\n",
       "      <th>...</th>\n",
       "      <th>VehAgeGLM</th>\n",
       "      <th>DrivAgeGLM</th>\n",
       "      <th>BonusMalusGLM</th>\n",
       "      <th>VehBrandGLM</th>\n",
       "      <th>VehGasGLM</th>\n",
       "      <th>LogDensityGLM</th>\n",
       "      <th>RegionGLM</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Severity</th>\n",
       "      <th>PurePremium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677998</th>\n",
       "      <td>677998</td>\n",
       "      <td>6114316.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.0, 9.0]</td>\n",
       "      <td>[41.0, 51.0)</td>\n",
       "      <td>76</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>4.0</td>\n",
       "      <td>R11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677999</th>\n",
       "      <td>677999</td>\n",
       "      <td>6114317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[51.0, 71.0)</td>\n",
       "      <td>53</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>8.0</td>\n",
       "      <td>R11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678000</th>\n",
       "      <td>678000</td>\n",
       "      <td>6114318.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.0, 9.0]</td>\n",
       "      <td>[41.0, 51.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>6.0</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678001</th>\n",
       "      <td>678001</td>\n",
       "      <td>6114319.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[51.0, 71.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>5.0</td>\n",
       "      <td>R25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678002</th>\n",
       "      <td>678002</td>\n",
       "      <td>6114320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[26.0, 31.0)</td>\n",
       "      <td>80</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>8.0</td>\n",
       "      <td>R11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678003</th>\n",
       "      <td>678003</td>\n",
       "      <td>6114321.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[26.0, 31.0)</td>\n",
       "      <td>80</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>9.0</td>\n",
       "      <td>R11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678004</th>\n",
       "      <td>678004</td>\n",
       "      <td>6114322.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[41.0, 51.0)</td>\n",
       "      <td>74</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>9.0</td>\n",
       "      <td>R11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678005</th>\n",
       "      <td>678005</td>\n",
       "      <td>6114323.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[31.0, 41.0)</td>\n",
       "      <td>80</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>7.0</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678006</th>\n",
       "      <td>678006</td>\n",
       "      <td>6114324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[41.0, 51.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>6.0</td>\n",
       "      <td>R93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678007</th>\n",
       "      <td>678007</td>\n",
       "      <td>6114325.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.0, 9.0]</td>\n",
       "      <td>[31.0, 41.0)</td>\n",
       "      <td>68</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>8.0</td>\n",
       "      <td>R93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678008</th>\n",
       "      <td>678008</td>\n",
       "      <td>6114326.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[51.0, 71.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>8.0</td>\n",
       "      <td>R93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678009</th>\n",
       "      <td>678009</td>\n",
       "      <td>6114327.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[41.0, 51.0)</td>\n",
       "      <td>95</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>9.0</td>\n",
       "      <td>R11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678010</th>\n",
       "      <td>678010</td>\n",
       "      <td>6114328.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.0, 9.0]</td>\n",
       "      <td>[41.0, 51.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>7.0</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678011</th>\n",
       "      <td>678011</td>\n",
       "      <td>6114329.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[51.0, 71.0)</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>5.0</td>\n",
       "      <td>R26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678012</th>\n",
       "      <td>678012</td>\n",
       "      <td>6114330.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>B12</td>\n",
       "      <td>...</td>\n",
       "      <td>(0.0, 9.0]</td>\n",
       "      <td>[26.0, 31.0)</td>\n",
       "      <td>54</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>4.0</td>\n",
       "      <td>R72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      IDpol  ClaimNb  Exposure  Area  VehPower  VehAge  \\\n",
       "677998      677998  6114316.0        0  0.005479     2       9.0     1.0   \n",
       "677999      677999  6114317.0        0  0.005479     5       7.0     0.0   \n",
       "678000      678000  6114318.0        0  0.005479     3       7.0     2.0   \n",
       "678001      678001  6114319.0        0  0.005479     3       4.0     0.0   \n",
       "678002      678002  6114320.0        0  0.002740     5       9.0     0.0   \n",
       "678003      678003  6114321.0        0  0.005479     5       4.0     0.0   \n",
       "678004      678004  6114322.0        0  0.005479     5       9.0     0.0   \n",
       "678005      678005  6114323.0        0  0.005479     4       4.0     0.0   \n",
       "678006      678006  6114324.0        0  0.005479     4       9.0     0.0   \n",
       "678007      678007  6114325.0        0  0.005479     5       6.0     4.0   \n",
       "678008      678008  6114326.0        0  0.002740     5       4.0     0.0   \n",
       "678009      678009  6114327.0        0  0.002740     5       4.0     0.0   \n",
       "678010      678010  6114328.0        0  0.002740     4       6.0     2.0   \n",
       "678011      678011  6114329.0        0  0.002740     2       4.0     0.0   \n",
       "678012      678012  6114330.0        0  0.002740     2       7.0     6.0   \n",
       "\n",
       "        DrivAge  BonusMalus VehBrand  ...   VehAgeGLM    DrivAgeGLM  \\\n",
       "677998     41.0        76.0      B12  ...  (0.0, 9.0]  [41.0, 51.0)   \n",
       "677999     51.0        53.0      B12  ...         NaN  [51.0, 71.0)   \n",
       "678000     48.0        50.0      B12  ...  (0.0, 9.0]  [41.0, 51.0)   \n",
       "678001     61.0        50.0      B12  ...         NaN  [51.0, 71.0)   \n",
       "678002     29.0        80.0      B12  ...         NaN  [26.0, 31.0)   \n",
       "678003     29.0        80.0      B12  ...         NaN  [26.0, 31.0)   \n",
       "678004     49.0        74.0      B12  ...         NaN  [41.0, 51.0)   \n",
       "678005     34.0        80.0      B12  ...         NaN  [31.0, 41.0)   \n",
       "678006     41.0        50.0      B12  ...         NaN  [41.0, 51.0)   \n",
       "678007     40.0        68.0      B12  ...  (0.0, 9.0]  [31.0, 41.0)   \n",
       "678008     54.0        50.0      B12  ...         NaN  [51.0, 71.0)   \n",
       "678009     41.0        95.0      B12  ...         NaN  [41.0, 51.0)   \n",
       "678010     45.0        50.0      B12  ...  (0.0, 9.0]  [41.0, 51.0)   \n",
       "678011     60.0        50.0      B12  ...         NaN  [51.0, 71.0)   \n",
       "678012     29.0        54.0      B12  ...  (0.0, 9.0]  [26.0, 31.0)   \n",
       "\n",
       "       BonusMalusGLM  VehBrandGLM  VehGasGLM  LogDensityGLM RegionGLM  \\\n",
       "677998            76          B12     Diesel            4.0       R11   \n",
       "677999            53          B12     Diesel            8.0       R11   \n",
       "678000            50          B12     Diesel            6.0       R82   \n",
       "678001            50          B12    Regular            5.0       R25   \n",
       "678002            80          B12     Diesel            8.0       R11   \n",
       "678003            80          B12    Regular            9.0       R11   \n",
       "678004            74          B12     Diesel            9.0       R11   \n",
       "678005            80          B12    Regular            7.0       R82   \n",
       "678006            50          B12     Diesel            6.0       R93   \n",
       "678007            68          B12    Regular            8.0       R93   \n",
       "678008            50          B12    Regular            8.0       R93   \n",
       "678009            95          B12    Regular            9.0       R11   \n",
       "678010            50          B12     Diesel            7.0       R82   \n",
       "678011            50          B12    Regular            5.0       R26   \n",
       "678012            54          B12     Diesel            4.0       R72   \n",
       "\n",
       "       Frequency Severity  PurePremium  \n",
       "677998       0.0      0.0          0.0  \n",
       "677999       0.0      0.0          0.0  \n",
       "678000       0.0      0.0          0.0  \n",
       "678001       0.0      0.0          0.0  \n",
       "678002       0.0      0.0          0.0  \n",
       "678003       0.0      0.0          0.0  \n",
       "678004       0.0      0.0          0.0  \n",
       "678005       0.0      0.0          0.0  \n",
       "678006       0.0      0.0          0.0  \n",
       "678007       0.0      0.0          0.0  \n",
       "678008       0.0      0.0          0.0  \n",
       "678009       0.0      0.0          0.0  \n",
       "678010       0.0      0.0          0.0  \n",
       "678011       0.0      0.0          0.0  \n",
       "678012       0.0      0.0          0.0  \n",
       "\n",
       "[15 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_clm_db['Frequency']   = pol_clm_db[\"ClaimNb\"] / pol_clm_db[\"Exposure\"]\n",
    "pol_clm_db[\"Severity\"]    = pol_clm_db[\"ClaimAmount\"] / np.fmax(pol_clm_db[\"ClaimNb\"], 1)\n",
    "pol_clm_db[\"PurePremium\"] = pol_clm_db[\"ClaimAmount\"] / pol_clm_db[\"Exposure\"]\n",
    "\n",
    "# check missing value\n",
    "pol_clm_db.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a90e1c-5d63-4ced-9873-8659ac453197",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Data subsets for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244984f3-324d-4d93-ba76-ffe051c5415c",
   "metadata": {},
   "source": [
    "**[Add Context for Task 3]**\n",
    "\n",
    "In this task, we will focus on creating train/test data sets for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6b020-967e-4791-9679-fd3ec9b763db",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "use `train_test_split` function from module sklearn.model_selection to split the data into training (90%) and testing (10%) (function parameters: test_size=0.1, random_state=210). Check if the resulting split for test and train data looks reasonable (similar) in terms of exposure percentage, claim number percentage, frequency and severity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c22081e-7c03-4d45-b58d-67cf1107ccc2",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf93f8d4-525c-4c5b-9625-026aabc6aa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Unnamed: 0      IDpol  ClaimNb  Exposure  Area  VehPower  VehAge  \\\n",
       " 674444      674444  6110762.0        0   0.08000     5       9.0     1.0   \n",
       " 31787        31787    65693.0        0   0.42000     4       9.0    12.0   \n",
       " 263814      263814  2127250.0        0   1.00000     3       5.0     3.0   \n",
       " 91515        91515  1008408.0        0   0.20000     2       5.0     6.0   \n",
       " 29347        29347    61332.0        0   1.00000     1       5.0    13.0   \n",
       " ...            ...        ...      ...       ...   ...       ...     ...   \n",
       " 51142        51142   103859.0        0   0.56000     1       6.0     6.0   \n",
       " 433030      433030  3152718.0        0   0.31000     4       4.0     4.0   \n",
       " 488428      488428  3254538.0        0   0.00274     4       6.0     2.0   \n",
       " 510055      510055  4050749.0        0   0.04000     5       4.0     0.0   \n",
       " 303626      303626  2215436.0        0   0.49000     4       9.0     8.0   \n",
       " \n",
       "         DrivAge  BonusMalus VehBrand  ... LogDensity  AreaGLM VehPowerGLM  \\\n",
       " 674444     40.0        50.0      B12  ...        8.0        5         9.0   \n",
       " 31787      28.0        58.0      B12  ...        7.0        4         9.0   \n",
       " 263814     64.0        50.0       B2  ...        6.0        3         5.0   \n",
       " 91515      49.0        50.0      B13  ...        4.0        2         5.0   \n",
       " 29347      39.0        50.0       B1  ...        4.0        1         5.0   \n",
       " ...         ...         ...      ...  ...        ...      ...         ...   \n",
       " 51142      36.0        54.0       B1  ...        3.0        1         6.0   \n",
       " 433030     32.0        50.0       B1  ...        6.0        4         4.0   \n",
       " 488428     35.0        85.0      B12  ...        7.0        4         6.0   \n",
       " 510055     23.0        85.0      B12  ...        8.0        5         4.0   \n",
       " 303626     46.0        50.0       B4  ...        7.0        4         9.0   \n",
       " \n",
       "          VehAgeGLM    DrivAgeGLM  BonusMalusGLM VehBrandGLM VehGasGLM  \\\n",
       " 674444  (0.0, 9.0]  [31.0, 41.0)             50         B12   Regular   \n",
       " 31787   (9.0, inf]  [26.0, 31.0)             58         B12    Diesel   \n",
       " 263814  (0.0, 9.0]  [51.0, 71.0)             50          B2    Diesel   \n",
       " 91515   (0.0, 9.0]  [41.0, 51.0)             50         B13    Diesel   \n",
       " 29347   (9.0, inf]  [31.0, 41.0)             50          B1    Diesel   \n",
       " ...            ...           ...            ...         ...       ...   \n",
       " 51142   (0.0, 9.0]  [31.0, 41.0)             54          B1    Diesel   \n",
       " 433030  (0.0, 9.0]  [31.0, 41.0)             50          B1   Regular   \n",
       " 488428  (0.0, 9.0]  [31.0, 41.0)             85         B12    Diesel   \n",
       " 510055         NaN  [21.0, 26.0)             85         B12    Diesel   \n",
       " 303626  (0.0, 9.0]  [41.0, 51.0)             50          B4   Regular   \n",
       " \n",
       "        LogDensityGLM  RegionGLM  \n",
       " 674444           8.0        R53  \n",
       " 31787            7.0        R82  \n",
       " 263814           6.0        R31  \n",
       " 91515            4.0        R52  \n",
       " 29347            4.0        R41  \n",
       " ...              ...        ...  \n",
       " 51142            3.0        R24  \n",
       " 433030           6.0        R82  \n",
       " 488428           7.0        R31  \n",
       " 510055           8.0        R72  \n",
       " 303626           7.0        R82  \n",
       " \n",
       " [610211 rows x 24 columns],\n",
       "         Unnamed: 0      IDpol  ClaimNb  Exposure  Area  VehPower  VehAge  \\\n",
       " 583250      583250  4174428.0        0      0.72     2       6.0    17.0   \n",
       " 164543      164543  1146791.0        0      0.93     3       7.0     6.0   \n",
       " 608939      608939  5032348.0        0      0.06     2       8.0     2.0   \n",
       " 420860      420860  3130884.0        0      0.83     3       9.0     2.0   \n",
       " 423281      423281  3135372.0        0      0.16     5       7.0     2.0   \n",
       " ...            ...        ...      ...       ...   ...       ...     ...   \n",
       " 116301      116301  1055298.0        0      1.00     1       7.0    18.0   \n",
       " 81463        81463   168790.0        0      1.00     4       5.0    15.0   \n",
       " 256717      256717  2113883.0        0      0.30     4       6.0     7.0   \n",
       " 69586        69586   147360.0        0      1.00     5       4.0    11.0   \n",
       " 25660        25660    54576.0        0      0.78     3       7.0     0.0   \n",
       " \n",
       "         DrivAge  BonusMalus VehBrand  ... LogDensity  AreaGLM VehPowerGLM  \\\n",
       " 583250     36.0        50.0       B2  ...        4.0        2         6.0   \n",
       " 164543     28.0        57.0      B10  ...        5.0        3         7.0   \n",
       " 608939     53.0        50.0      B12  ...        4.0        2         8.0   \n",
       " 420860     51.0        50.0      B11  ...        5.0        3         9.0   \n",
       " 423281     28.0        60.0       B1  ...        9.0        5         7.0   \n",
       " ...         ...         ...      ...  ...        ...      ...         ...   \n",
       " 116301     27.0        72.0       B1  ...        3.0        1         7.0   \n",
       " 81463      45.0        50.0       B4  ...        6.0        4         5.0   \n",
       " 256717     52.0        50.0       B1  ...        7.0        4         6.0   \n",
       " 69586      39.0        56.0       B1  ...        8.0        5         4.0   \n",
       " 25660      76.0        50.0       B1  ...        6.0        3         7.0   \n",
       " \n",
       "          VehAgeGLM    DrivAgeGLM  BonusMalusGLM VehBrandGLM VehGasGLM  \\\n",
       " 583250  (9.0, inf]  [31.0, 41.0)             50          B2    Diesel   \n",
       " 164543  (0.0, 9.0]  [26.0, 31.0)             57         B10    Diesel   \n",
       " 608939  (0.0, 9.0]  [51.0, 71.0)             50         B12    Diesel   \n",
       " 420860  (0.0, 9.0]  [51.0, 71.0)             50         B11    Diesel   \n",
       " 423281  (0.0, 9.0]  [26.0, 31.0)             60          B1   Regular   \n",
       " ...            ...           ...            ...         ...       ...   \n",
       " 116301  (9.0, inf]  [26.0, 31.0)             72          B1   Regular   \n",
       " 81463   (9.0, inf]  [41.0, 51.0)             50          B4   Regular   \n",
       " 256717  (0.0, 9.0]  [51.0, 71.0)             50          B1    Diesel   \n",
       " 69586   (9.0, inf]  [31.0, 41.0)             56          B1   Regular   \n",
       " 25660          NaN   [71.0, inf)             50          B1   Regular   \n",
       " \n",
       "        LogDensityGLM  RegionGLM  \n",
       " 583250           4.0        R31  \n",
       " 164543           5.0        R52  \n",
       " 608939           4.0        R22  \n",
       " 420860           5.0        R24  \n",
       " 423281           9.0        R82  \n",
       " ...              ...        ...  \n",
       " 116301           3.0        R24  \n",
       " 81463            6.0        R24  \n",
       " 256717           7.0        R93  \n",
       " 69586            8.0        R53  \n",
       " 25660            6.0        R24  \n",
       " \n",
       " [67802 rows x 24 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trn_db, tst_db = train_test_split(pol_clm_db, test_size=0.1, random_state=210)\n",
    "\n",
    "trn_db, tst_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb51223-cff7-4d6c-996a-652f604ff097",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4 Modeling (Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2d81e-b171-4ec5-9dbb-437c9ac9973b",
   "metadata": {},
   "source": [
    "**[Add Context for Task 4]**\n",
    "\n",
    "From previous task, we observe a slight bias in terms of frequency and severity between two data sets, which could be further analyzed w.r.t. the available features (i.e. whether we also have a feature shift), and one could also consider a stratified choice of learning and test data sets. Here, we refrain from doing so.\n",
    "\n",
    "With the prepared dataset ready, we can safely kick off the modeling part. In the following, we will fit various claim frequency models based on Poisson assumption:\n",
    "\n",
    "All insurance policies i = 1, 2, ... can be described by independent claim counts $N_i$ having distribution \n",
    "\n",
    "$$ N_i \\sim Poi (\\lambda(x_i) \\nu_i) $$\n",
    "\n",
    "that is, claim counts can be modeled by independent Poisson distributions, and the aim is to estimate (infer) the regression function $\\lambda()$, describing the expected frequency w.r.t. exposure $\\nu_i$ > 0, from the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25228e-cd5d-467a-aeaf-f8abb5719c45",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "Define a function for calculating average poisson deviance (see definition below).\n",
    "\n",
    "The (scaled) Poisson deviance loss for expected frequency $\\lambda > 0 $ is defined by \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D^{*}(\\boldsymbol{N}, \\lambda) &=\\sum_{i=1}^{n} 2 N_{i}\\left[\\frac{\\lambda v_{i}}{N_{i}}-1-\\log \\left(\\frac{\\lambda v_{i}}{N_{i}}\\right)\\right] \\geq 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $N_i$ is the number of claims, $ v_i$ is the exposure, and the $i^{th}$ term is set equal to $2\\lambda v_i$ for $N_i = 0$\n",
    "\n",
    "For fair comparison of results, we define average deviance loss as (scaled) Poisson deviance divided by the number of policy (n), i.e.\n",
    "\n",
    "$$\\frac{D^{*}(\\boldsymbol{N}, \\lambda)}{n} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493eba0-7784-4164-8bf7-e1fba77f0b90",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9961dc0-a013-4dd9-9291-38fd73cb9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we are going to compare various models, we create a table which stores the metrics we are going to use for the comparison and the selection of the best model.\n",
    "\n",
    "mod_res = pd.DataFrame(\n",
    "    {'model'             : pd.Series(dtype='str'),\n",
    "     'in_sample_loss'    : pd.Series(dtype='float'),\n",
    "     'out_sample_loss'   : pd.Series(dtype='float'),\n",
    "     'aic'               : pd.Series(dtype='float'),\n",
    "     'in_sample_gini'    : pd.Series(dtype='float'),\n",
    "     'out_sample_gini'   : pd.Series(dtype='float'),\n",
    "     'number_of_param'   : pd.Series(dtype='int')\n",
    "     })\n",
    "     \n",
    "# av_poisson_deviance: average possion deviance, which is defined as scaled possion deviance divided by the number of observations\n",
    "def av_poisson_deviance(y_freq, p_freq, exposure):\n",
    "    ____________\n",
    "    ____________\n",
    "    ____________\n",
    "    ____________\n",
    "\n",
    "y_freq_trn   = trn_db['Frequency']\n",
    "y_trn        = trn_db['ClaimNb']\n",
    "expo_trn     = trn_db['Exposure']\n",
    "\n",
    "y_freq_tst   = tst_db['Frequency']\n",
    "y_tst        = tst_db['ClaimNb']\n",
    "expo_tst     = tst_db['Exposure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0433d-6433-43af-a2af-d3deec0d4339",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5 GLM0: Homogeneous model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdef3ae-f413-4b2c-87ba-9167f9d45398",
   "metadata": {},
   "source": [
    "**[Add Context for Task 5]**\n",
    "\n",
    "Build first naive GLM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f89d7c7-6825-4c84-996c-618097d551c8",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "Build Homogeneous model, the trivial model where we estimate the global mean and no features are included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be3bac-16a0-4c33-b69e-6dde59c365cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511f860-f77e-4627-aa31-56a3c80dec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import helper\n",
    "\n",
    "GLM_freq_homo = smf.glm(\n",
    "   \"ClaimNb ~ 1\",\n",
    "    data=df_train_mod, exposure=np.asarray(df_train_mod['Exposure']),\n",
    "    family=sm.families.Poisson(sm.genmod.families.links.log()),\n",
    ").fit()\n",
    "\n",
    "p_freq_trn = np.repeat(np.exp(GLM_freq_homo.params[0]), len(trn_db))\n",
    "p_freq_tst = np.repeat(np.exp(GLM_freq_homo.params[0]), len(tst_db))\n",
    "\n",
    "mod_res = helper.store_mod_res(mod_res, GLM_freq_homo, \"GLM_freq_homo\", y_freq_trn, p_freq_trn, expo_trn, y_freq_tst, p_freq_tst, expo_tst)\n",
    "print(GLM_freq_homo.summary())\n",
    "print(mod_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b1c36e-2d69-4967-899a-8e113cc0db12",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6 GLM1: all feature components considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec218532-4a48-4a3f-862e-a64c3ba7c5b0",
   "metadata": {},
   "source": [
    "**[Add Context for Task 6]**\n",
    "\n",
    "Build GLM for all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5fe42-e7bb-4ab5-954b-4ad27f8f5497",
   "metadata": {
    "tags": []
   },
   "source": [
    "**[Instructions]**\n",
    "\n",
    "Build GLM model for all features included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f721a329-b009-47b5-9621-eba37d611588",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c787c4-8743-4f02-aed7-4840dab174bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AreaGLM', 'VehPowerGLM', 'VehAgeGLM', 'DrivAgeGLM', 'BonusMalusGLM', 'VehBrandGLM', 'VehGasGLM', 'LogDensityGLM', 'RegionGLM']\n",
    "GLM_freq_all = smf.glm(\n",
    "    _______________\n",
    ").fit()\n",
    "\n",
    "p_freq_trn = GLM_freq_all.predict(____________)\n",
    "p_freq_tst = GLM_freq_all.predict(____________)\n",
    "\n",
    "mod_res = helper.store_mod_res(mod_res, GLM_freq_all, \"GLM_freq_all\", y_freq_trn, p_freq_trn, expo_trn, y_freq_tst, p_freq_tst, expo_tst)\n",
    "\n",
    "print(GLM_freq_all.summary())\n",
    "mod_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4a0ed-3557-436c-80c3-a47e064eb140",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7 GLM2: drop feature components Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff319d-3bc5-41ae-8733-1a2882ee8033",
   "metadata": {},
   "source": [
    "**[Add Context for Task 7]**\n",
    "\n",
    "A detailed analysis of the output provides that all considered features are significant, except the area code AreaGLM. This can be seen from the p-value, which is above 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf5913-c802-417f-bf65-97d35d545242",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "Drop the feature 'AreaGLM' and inspect the model result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15142dfd-447a-49b6-be85-c87ee7df323a",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57bf74-d665-4f8d-a1cd-4894b12bc692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_exc_area = ['VehPowerGLM', 'VehAgeGLM', 'DrivAgeGLM', 'BonusMalusGLM', 'VehBrandGLM', 'VehGasGLM', 'LogDensityGLM', 'RegionGLM']\n",
    "GLM_freq_exc_area = smf.glm(\n",
    "    _______________\n",
    ").fit()\n",
    "\n",
    "p_freq_trn = GLM_freq_exc_area.predict(____________)\n",
    "p_freq_tst = GLM_freq_exc_area.predict(____________)\n",
    "\n",
    "mod_res = helper.store_mod_res(mod_res, GLM_freq_exc_area, \"GLM_freq_exc_area\", y_freq_trn, p_freq_trn, expo_trn, y_freq_tst, p_freq_tst, expo_tst)\n",
    "\n",
    "print(GLM_freq_exc_area.summary())\n",
    "mod_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6389a01e-e42e-4384-a77e-5c184f72b423",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8 SBS (standardized binary splits) Regression trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de32b9-978e-4e86-8bd0-c2ddf0619a19",
   "metadata": {},
   "source": [
    "**[Add Context for Task 8]**\n",
    "\n",
    "Regression tree models are based on partitioning the feature space in an optimal way to receive (more) homogeneity on the resulting subsets. The optimal partition of the feature space is determined recursively by searching for the stage-wise optimal split among all standardized binary splits (SBS).\n",
    "\n",
    "Pre-processing for the regression trees in our case, please note that \n",
    "\n",
    "1. if there is a natural order in a categorical feature component, then this feature should be replaced by an increasing sequence of real numbers\n",
    "\n",
    "2. It can be computationally very expensive if we have many (unordered) categorical feature components with many possible values and/or many leaves of the current tree.\n",
    "\n",
    "3. the pre processing per se won't bring any advantage/disadvantage to the performance of regression trees compared with GLM. It's the other way to rephrase the format of data (no feature engineering involved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fcbcb-a164-4aab-a3cc-dde213aee873",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "(1) Use `DecisionTreeRegressor` to build a regression tree for claim frequency. Keep in mind that:\n",
    "\n",
    "- set `ccp_alpha` to be 0.00005. The parameter controls minimal cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting. A smaller value gives a bigger tree.\n",
    "\n",
    "- set `min_samples_leaf` to be 10,000. The parameter set minimum number of samples required to be at a leaf node. Is this value too restrictive? \n",
    "\n",
    "\n",
    "(2) In the model `fit()` method, few options are provided, which one would fit our aim (building frequency model). More specifically, how to specify our target variable in Decision Tree Regression when exposure exists.\n",
    "\n",
    "`fit(X, y, sample_weight=None, check_input=True, X_idx_sorted='deprecated')`\n",
    "\n",
    "`sample_weight`: array-like of shape (n_samples,), default=None\n",
    "If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.\n",
    "\n",
    "\n",
    "a) DecisionTree.fit(X_trn, ClaimNb, sample_weight=None) \n",
    "\n",
    "b) DecisionTree.fit(X_trn, ClaimNb, sample_weight=Exposure) \n",
    "\n",
    "c) DecisionTree.fit(X_trn, Frequency, sample_weight=None) \n",
    "\n",
    "d) DecisionTree.fit(X_trn, Frequency, sample_weight=Exposure) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b3e72-24b4-4f52-8573-ed426d173cd7",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0676bb-fd49-4622-966c-39c80406bdb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# one hot encoding for variable VehBrandGLM VehGasGLM RegionGLM as DecisionTreeRegressor can only deal with numerical values\n",
    "feat_cnt = ['AreaGLM', 'BonusMalusGLM', 'LogDensityGLM'] # continuous features\n",
    "feat_cat  = ['VehPowerGLM', 'VehAgeGLM', 'DrivAgeGLM', 'VehBrandGLM', 'VehGasGLM', 'RegionGLM']\n",
    "\n",
    "onehot_coded_trn_db = pd.get_dummies(trn_db[feat_cat])\n",
    "onehot_coded_tst_db = pd.get_dummies(tst_db[feat_cat])\n",
    "\n",
    "X_trn = pd.concat([trn_db[feat_cnt], onehot_coded_trn_db], axis=1)\n",
    "X_tst = pd.concat([tst_db[feat_cnt], onehot_coded_tst_db], axis=1)\n",
    "\n",
    "y_trn = trn_db['Frequency']\n",
    "y_tst = tst_db['Frequency']\n",
    "\n",
    "# criterion = poisson in DecisionTree seems not work very well. So in this case, we use default loss function to split the tree. The result can be regarded as a good approximation to the optimal split as long as data size is large enough.\n",
    "RT0_freq = DecisionTreeRegressor(_______________) \n",
    "\n",
    "RT0_freq.fit(_____________) \n",
    "\n",
    "p_freq_trn = _______________\n",
    "p_freq_tst = _______________\n",
    "\n",
    "mod_res = helper.store_mod_res(mod_res, RT0_freq, \"RT0_freq\", y_freq_trn, p_freq_trn, expo_trn, y_freq_tst, p_freq_tst, expo_tst, isGLM=False)\n",
    "mod_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c1d0a-bdac-4f7b-b2f2-184a4f53eb49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9 Plot SBS result (No answer required for this question; just read the code and continue the next question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f2adc-720d-45a8-abfe-1f1111c1088e",
   "metadata": {},
   "source": [
    "**[Add Context for Task 9]**\n",
    "\n",
    "we don't dive too much deep in hyperparameter tunings.\n",
    "\n",
    "min_samples_leaf: 100000 implies that we only consider SBS such that each leaf receives at least 100000 policies. This choice can be rather restrictive, for instance, the number of policies in training with a bonus-malus level bigger than 100 is 7,029. Requiring at least 10,000 policies in each leaf, the SBS is not able to distinguish different malus levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365f1ba-e0f3-418b-b850-f1ef089471b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "**[Instructions]**\n",
    "\n",
    "plot the SBS result using function plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8ee22-0fe8-416a-9157-3d738389549b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60567f41-93bc-4103-a675-087d1451894c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(10,8), dpi=150)\n",
    "plot_tree(RT0_freq, feature_names=X_trn.columns, proportion=True)\n",
    "\n",
    "from sklearn.tree import export_text\n",
    "r = export_text(r = export_text(RT0_freq, feature_names=X_trn.columns.tolist()))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5648363-7f09-4a54-bc6b-fec5379b6161",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 10 Evaluation of the calibration of prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec7108-ccbd-475c-bc55-ad472b50542b",
   "metadata": {},
   "source": [
    "**[Add Context for Task 10]**\n",
    "\n",
    "(1) VehAge = 0, VehBrand = B12, VehGas = regular gas fuel (not diesel)\n",
    "\n",
    "|--- VehAgeGLM_[-inf, 1.0) >  0.50\n",
    "|   |--- VehBrandGLM_B12 >  0.50\n",
    "|   |   |--- VehGasGLM_Diesel <= 0.50\n",
    "|   |   |   |--- value: [0.67]\n",
    "\n",
    "\n",
    "(2) The feature selection and pre-processing has not been done properly for the GLM, in particular, we have not been studying interactions in feature components in GLM. For example, such interactions exist between `VehAge`, `VehBrand` and `VehGas`.\n",
    "\n",
    "__Business insights__\n",
    "\n",
    "Thus, there seems to be an issue with new regular fuel cars of brand B12. By a detailed investigation, we find that:\n",
    "\n",
    "(1) Brand B12 has by far the newest cars (VehAge = 0).\n",
    "(2) B12 has more than 45,000 cars with an exposure of less than 50 days. This is a sign that many of these car belong to\n",
    "a car fleet, possibly a car rental company. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410fa954-606d-45bd-b2b2-69fb23ada275",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "To ensure that estimators yield reasonable predictions for different policyholder types, use function `helper.plot_obs_pred()` to plot observation v.s. model predicted value for variables you have interest in.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce244309-3842-4c29-ae5c-b836ccb0a8b1",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3250aa2-05c6-4482-955d-aa1e3b1171c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "helper.plot_obs_pred(\n",
    "    df=trn_db,\n",
    "    feature=________,\n",
    "    weight=\"Exposure\",\n",
    "    observed=\"Frequency\",\n",
    "    predicted=GLM_freq_exc_area.predict(trn_db[feat_exc_area]),\n",
    "    y_label=\"Claim Frequency\",\n",
    "    title=\"train data (GLM)\"\n",
    ")\n",
    "\n",
    "helper.plot_obs_pred(\n",
    "    df=tst_db,\n",
    "    feature=________,\n",
    "    weight=\"Exposure\",\n",
    "    observed=\"Frequency\",\n",
    "    predicted=GLM_freq_exc_area.predict(tst_db[feat_exc_area]),\n",
    "    y_label=\"Claim Frequency\",\n",
    "    title=\"test data (GLM)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6e0bb3-a2ac-4b57-a0ab-51dc238c3f86",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 11 Severity modeling -- Attritional part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796848d-03dd-4a55-b7e7-d3be3df55b46",
   "metadata": {
    "tags": []
   },
   "source": [
    "**[Add Context for Task 11]**\n",
    "\n",
    "As the procedure in this section has not big difference from previous one. We won't repeat the work in this part. The mean claim amount or severity can be empirically shown to follow approximately a Gamma distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935beec-f41b-4579-b131-d321b25d3475",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "Build GLM for the attritional severity model:\n",
    "\n",
    "We fit a GLM model for the severity with the same features (Variable ``AreaGLM`` excluded) as we did in `GLM_exc_area`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b3f235-2e75-4e11-93e8-816e68084d01",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a266b11-6916-4c4b-b973-f8e34170ebfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 190_000\n",
    "\n",
    "mask_trn = (trn_db[\"ClaimAmount\"] > 0) & (trn_db[\"ClaimAmount\"] < threshold)\n",
    "mask_tst = (tst_db[\"ClaimAmount\"] > 0) & (tst_db[\"ClaimAmount\"] < threshold)\n",
    "mask_trn_ll = (trn_db[\"ClaimAmount\"] > 0) & (trn_db[\"ClaimAmount\"] >= threshold)\n",
    "mask_tst_ll = (tst_db[\"ClaimAmount\"] > 0) & (tst_db[\"ClaimAmount\"] >= threshold)\n",
    "\n",
    "trn_sev_attr_db    = trn_db[mask_trn]\n",
    "tst_sev_attr_db    = tst_db[mask_tst]\n",
    "trn_sev_ll_db      = trn_db[mask_trn_ll]\n",
    "tst_sev_ll_db      = tst_db[mask_tst_ll]\n",
    "\n",
    "feat_exc_area = ['VehPowerGLM', 'VehAgeGLM', 'DrivAgeGLM', 'BonusMalusGLM', 'VehBrandGLM', 'VehGasGLM', 'LogDensityGLM', 'RegionGLM']\n",
    "\n",
    "GLM_sev_exc_area = smf.glm(\n",
    "    ______________\n",
    ").fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b6acf2-6a3d-445e-8edd-c4aa22568b61",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12 Large loss part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502638e-e176-4351-8c4f-af6a1b8f1024",
   "metadata": {
    "tags": []
   },
   "source": [
    "**[Add Context for Task 12]**\n",
    "\n",
    "Build GLM for the large loss model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157bc0e8-d0c5-461e-ae3c-6f9e1d34f904",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "Build GLM for the large loss model:\n",
    "\n",
    "- Since we only have 20 large loss claims, it's very difficult to build a reasonable large loss model based on this tiny data set. Therefore, people in this project are recommended to build a flat loading model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850e673-b022-4494-8305-14731611aca0",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8dd603-a84b-46ad-91aa-ec13796a172c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# average large loss in train sample\n",
    "av_excess_ll = np.average(trn_sev_ll_db['ClaimAmount'] - threshold)\n",
    "prob_ll      = len(trn_sev_ll_db)/(len(trn_sev_ll_db) + len(trn_sev_attr_db))\n",
    "flat_loading = av_excess_ll * prob_ll\n",
    "\n",
    "GLM_sev_homo = smf.glm(\n",
    "    ___________________\n",
    ").fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70a5f1-5910-4941-8db0-2678eb2513b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 13 Model combiner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbfd47f-3c5a-4c86-a15a-e5f580cda8b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "**[Add Context for Task 13]**\n",
    "\n",
    "Combine frequency and severity model together and caculate predictive pure premium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55199b47-7d2e-458b-a96a-ca11f55cdfce",
   "metadata": {},
   "source": [
    "**[Instructions]**\n",
    "\n",
    "Combine 3 models built in previous section together, i.e.\n",
    "\n",
    "1. `GLM_exc_area`\n",
    "2. `GLM_sev_exc_area`\n",
    "3. `flat_loading` for large loss\n",
    "\n",
    "$$ pure \\ premium = freq * (attritional \\ cost + flat \\ loading) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b16d53-84ac-482e-93b3-b4bd6873f2c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321eeb2-9c82-425a-9dff-574061cc57d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trn_db['PredictiveFrequency']   = ____________\n",
    "trn_db['PredictiveSeverity']    = ____________\n",
    "trn_db['PredictivePurePremium'] = ____________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a679abd630bd194c89f24a2b60a8328b20741a78fa58123a88fd9895fa9693f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
